{
  "hash": "a4d90321a18e1eacaa9997d1c8edf57f",
  "result": {
    "markdown": "---\ntitle: \"Recent developments in scNavigator\"\nauthor: \"Konstantin Zaitsev\"\ndate: \"14/09/2022\"\nformat: \n  revealjs: \n    slide-number: true\n    theme: [libs/itmo.scss]\n    footer: \"Artyomov Lab Meeting (Sep 14th 2022)\"\neditor: source\n---\n\n\n## scRNA-seq is on the rise\n\nPublications based on pubmed results \"single cell rna sequencing\"\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lab_meeting_2022_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## Drop-seq schematics\n\n\n![](images/scheme_3.png)\n\n::: footer\nPaper: [https://www.cell.com/abstract/S0092-8674(15)00549-8](https://www.cell.com/abstract/S0092-8674(15)00549-8)\n:::\n\n---\n\n## Barcoding\n\n![](images/barcoded_beads-04.png)\n\n\n---\n\n\n## Drop-seq schematics\n\n![](images/scheme_3.png)\n\n::: footer\nPaper: [https://www.cell.com/abstract/S0092-8674(15)00549-8](https://www.cell.com/abstract/S0092-8674(15)00549-8)\n:::\n\n\n---\n## Sequencing\n\n![](images/umis7.png)\n\n\n---\n\n\n## Sequencing\n\n![](images/umis8.png)\n\n---\n\n## Creating a map of the dataset\n\n\n![](images/pbmc_katyas.png)\n\n\n::: footer\nPaper: [https://nn.neurology.org/content/nnn/7/4/e732.full.pdf](https://nn.neurology.org/content/nnn/7/4/e732.full.pdf)\n:::\n\n---\n\n\n## scNavigator\n\n[https://artyomovlab.wustl.edu/scn/](https://artyomovlab.wustl.edu/scn/)\n\n![](images/schematic.png)\n\n## scNavigator\n\n-  Web tool for visual analysis of scRNA-seq data: gene expression plots, pathway expression plots, clustering and so on\n-  Database of uniformly processed public scRNA-seq datasets\n-  Gene signature search / single gene search through public scRNA-seq datasets\n\n## scNavigator (code base)\n\n- scNavigator - [https://github.com/ctlab/scNavigator](https://github.com/ctlab/scNavigator). \n\nKotlin server side + a lot of JavaScript client side.\n\n\n- scn-pipeline - [https://github.com/ctlab/scn-pipeline](https://github.com/ctlab/scn-pipeline). \n\nSnakemake pipeline for processing public datasets.\n\n\n- scnPrep - [https://github.com/ctlab/SCNPrep](https://github.com/ctlab/SCNPrep). \n\nR package to convert Seurat objects to format of scNavigator.\n\n\n## scn-pipeline\n\n-  Spring/Summer 2022\n-  Huge rework of the old code base from Maria Firuleva\n-  Old: custom scripts that would generate analysis pipeline specific for the platform (Slurm or LSF)\n-  Currently: one snakemake pipeline that does everything (you can use slurm or LSF profiles to run the pipeline)\n\n## scn-pipeline: current and future plans\n\nRepo:\n\n-  Github Repo: [https://github.com/ctlab/scn-pipeline](https://github.com/ctlab/scn-pipeline)\n-  Please use [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/)\n-  Releases and changelogs are generated by `release-please` github action, that parses conventional commits for changes\n-  Documentation [https://scn-pipeline.readthedocs.io/en/latest/](https://scn-pipeline.readthedocs.io/en/latest/) is build automatically from `docs`\n\nBranches:\n\n-  Branch \"main\" - only processing until Seurat file\n-  Branch \"scn\" (work in progress) - all additional rules specific to SCN and lab in general (conversion of seurat object to internal SCN format, calculating PCAs for GESECA and any other file reformatting)\n\n\n## scn-pipeline, how to run\n\nPut the dataset you want to process in the `config/datasets.json` file as a list of datasets, example below.\n\n```{{json}}\n[\"GSE145241\", \"GSE116240\"]\n```\n\nand then simply execute two rules (example for local execution):\n\n```{{bash}}\nsnakemake -j 4 --use-conda get_all_meta\nsnakemake -j 4 --use-conda process_all\n```\n\n-  `get_all_meta` - will obtain all the meta information about the dataset required for processing\n-  `process_all` - will use the obtained meta and process the datasets\n\n\n## `get_all_meta`\n\n::: columns\n::: {.column width=\"60%\"}\n-   We use [FFQ](https://github.com/pachterlab/ffq) to obtain meta information about the dataset: samples, runs, paths to files, MD5sums for ftp files, species and so on\n-   We get the 10x whitelists from cellranger\n-   We use python scripts to obtain all additional information about the dataset: technology, version, which files to use (fastq-dump or get the files from FTP) and we mark read files as `cdna`, `barcode` or `index`\n-   We combine the results for all datasets\n:::\n\n::: {.column width=\"40%\"}\n![](images/meta_rulegraph.svg)\n:::\n:::\n\n::: footer\nFFQ - [https://github.com/pachterlab/ffq](https://github.com/pachterlab/ffq)\n:::\n\n## `get_all_meta`\n\n::: columns\n::: {.column width=\"60%\"}\n-   It's important that **for every dataset after this step we know the technology and version** and this technology should be supported by our pipeline\n:::\n\n::: {.column width=\"40%\"}\n![](images/meta_rulegraph.svg)\n:::\n:::\n\n## `get_all_meta` - known problems\n\n::: columns\n::: {.column width=\"60%\"}\n\nNo NCBI API key:\n\n-   FFQ doesn't allow to provide NCBI API KEY\n-   if you submit to many requests in parallel it can fail to return the results\n-   solution: resubmit the rule\n-   hardcore solution: pull request to FFQ with the feature\n\nNCBI FTP is unreliable:\n\n-   If we can't identify the technology using fastq-dump, we look for files in FTP. And FTP is quite often down.\n-   solution: resubmit the rule later\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/meta_rulegraph.svg)\n:::\n:::\n\n\n## `get_all_meta` - known problems\n\n::: columns\n::: {.column width=\"60%\"}\n\nDifferent parts of NCBI API can change:\n\n-   FFQ might return different results later (it already happened once)\n-   solution: there is really none, just to be conscious about it\n:::\n\n::: {.column width=\"40%\"}\n![](images/meta_rulegraph.svg)\n:::\n:::\n\n\n## `process_all`\n\n::: columns\n::: {.column width=\"50%\"}\n-   For each run: we get the raw files using `parallel-fastq-dump` or downloading them from FTP (if SRA files are not good)\n-   For species: we use STAR index build on of cellranger fasta and gtf files\n-   For sample: we create a STAR (STARSolo) script that combines raw files from all the runs, and then run it\n:::\n\n::: {.column width=\"50%\"}\n![](images/process_rulegraph.svg)\n:::\n:::\n\n\n## STARSolo instead of kallisto {.smaller}\n\n|           |            | % pseudoaligned   | % aligned to gene |\n|-----------|------------|-------------------|-------------------|\n| Dataset   | Sample     | Kallisto bustools | STARSolo          |\n| GSE124494 | GSM3535276 |             58.20 |             59.80 |\n|           | GSM3535277 |             58.00 |             60.13 |\n|           | GSM3535278 |             27.70 |             29.07 |\n|           | GSM3535279 |             61.70 |             64.99 |\n|           | GSM3535280 |             59.30 |             61.65 |\n|           | GSM3535281 |             56.20 |             57.74 |\n| GSE155593 | GSM4708389 |             57.90 |             60.71 |\n|           | GSM4708390 |             58.90 |             61.39 |\n| GSE185890 | GSM5625332 |             56.70 |             53.79 |\n|           | GSM5625333 |             54.80 |             51.95 |\n\n## STARSolo instead of kallisto {.smaller}\n\n|               |            | Speed (read per second) |            |            |\n|---------------|------------|-------------------------|------------|------------|\n| Dataset       | Sample     | Kallisto bustools       | Alevin fry | STARSolo   |\n| GSE124494     | GSM3535276 |              332,907.70 | 250,619.42 | 102,663.21 |\n|               | GSM3535277 |              315,435.09 | 264,855.05 |  98,317.58 |\n|               | GSM3535278 |              488,236.53 | 392,851.08 | 195,205.96 |\n|               | GSM3535279 |              314,108.38 | 224,630.20 |  98,614.58 |\n|               | GSM3535280 |              304,400.29 | 211,894.14 |  94,517.14 |\n|               | GSM3535281 |              325,220.98 | 205,816.24 | 102,972.63 |\n| GSE155593     | GSM4708389 |              247,426.65 | 302,396.01 |  76,950.31 |\n|               | GSM4708390 |              238,196.30 | 278,436.23 |  80,355.54 |\n| GSE185890     | GSM5625332 |              232,489.18 | 303,885.39 | 107,534.46 |\n|               | GSM5625333 |              237,147.57 | 317,799.00 | 106,614.43 |\n| Average speed |            |              303,556.87 | 275,318.27 | 106,374.58 |\n\n## STARSolo instead of kallisto\n\n-  STAR seems to be a bit better than kallisto in alignment quality\n-  Only 2-3 times slower\n-  Allows more QC\n-  Allows to easier add new technologies due to barcode geometry\n-  Supports two types of filtering: \n\n```\n--soloCellFilter  CellRanger2.2 # Knee filtering is similar to the method used by CellRanger 2.2.x.\n--soloCellFilter  EmptyDrops_CR # EmptyDrop-like filtering used by CellRanger >= 3.0.0\n```\n\n::: footer\n[https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md](https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md)\n:::\n\n## STARSolo barcode geometry\n\n![](images/barcode_geometry.png)\n\n::: footer\n[https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md](https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md)\n:::\n\n## STARSolo barcode geometry\n\n![](images/barcode_geometry2.png)\n\n::: footer\n[https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md](https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md)\n:::\n\n\n## `process_all`: Seurat analysis\n\n::: columns\n::: {.column width=\"50%\"}\n-   [MiQC](https://bioconductor.org/packages/release/bioc/html/miQC.html) to remove cells with high mitochondrial content\n-   SCTransform to normalize\n-   PCA\n-   TSNE / UMAP (from 20 PCA dims)\n-   Clustering (from 20 PCA dims)\n-   Markers / Averaged expression / PCT expression\n-   Integration is done using approach described in [here](https://www.cell.com/cell/fulltext/S0092-8674(19)30559-8) on SCTransform'ed datasets\n:::\n\n::: {.column width=\"50%\"}\n![](images/process_rulegraph.svg)\n:::\n:::\n\n::: footer\nVignette for integration: [https://satijalab.org/seurat/articles/integration_introduction.html#performing-integration-on-datasets-normalized-with-sctransform-1](https://satijalab.org/seurat/articles/integration_introduction.html#performing-integration-on-datasets-normalized-with-sctransform-1)\n\nPublication: [Comprehensive Integration of Single-Cell Data](https://www.cell.com/cell/fulltext/S0092-8674(19)30559-8)\n:::\n\n## Results of the pipeline\n\n-  Seurat RDS files (for samples and merged datasets)\n-  Markers / Average expression / Averaged pct expression\n-  STAR QC tables \n-  QC Plots\n\n## scn-pipeline: current and future plans\n\nRepo:\n\n-  Github Repo: [https://github.com/ctlab/scn-pipeline](https://github.com/ctlab/scn-pipeline)\n-  Please use [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/)\n-  Releases and changelogs are generated by `release-please` github action, that parses conventional commits for changes\n-  Documentation [https://scn-pipeline.readthedocs.io/en/latest/](https://scn-pipeline.readthedocs.io/en/latest/) is build automatically from `docs`\n\nBranches:\n\n-  Branch \"main\" - only processing until Seurat file\n-  Branch \"scn\" (work in progress) - all additional rules specific to SCN and lab in general (conversion of seurat object to internal SCN format, calculating PCAs for GESECA and any other file reformatting)\n\n## scNavigator\n\n- [https://artyomovlab.wustl.edu/scn/](https://artyomovlab.wustl.edu/scn/) - master\n- [https://artyomovlab.wustl.edu/scn-dev/](https://artyomovlab.wustl.edu/scn/) - dev-single-gene-search\n\nCurrent development version has many changes and quality of life improvements compared to master:\n\n- Percentage option on bar plots\n- Density plots\n- Filtering tab has subsampling (to subsample dataset with a lot of cells)\n- Pathways (coloring scheme, returns overlapping genes)\n- Single gene search\n\n## Gene Signature Search\n\n![](images/gss.png)\n\n\n## Single Gene Search\n\n-  Idea is to find datasets and clusters where certain gene is expressed\n-  Problem with the markers: if you only have T cells in the datasets, T-cell markers will not appear in markers (results of DE)\n-  Hard to implement negative search (I want to find clusters with gene A, but not gene B)\n\n## TF-IDF\n\nTF-IDF is term frequency–inverse document frequency\n\n- Words are terms, we have $|U_0|$ terms\n- $U_i$ are documents\n- $tf(g, U_i) = 1$ if $g \\in U_i$ and $0$ otherwise\n- $idf(g) = log(\\frac{N}{|\\{U_i | g \\in U_i\\}|})$\n- $tfidf(g, U_i) = tf(g, U_i) * idf(g)$\n\n## TF-IDF\n\nTF-IDF is term frequency–inverse document frequency\n\n- Genes are terms, we have $|U_0|$ terms\n- $U_i$ are clusters\n- $tf(g, U_i) = \\%$, in how many cells gene $g$ is expressed\n- $idf(g) = log(\\frac{total\\ number\\ of\\ cells}{total\\ number\\ of\\ cells\\ with\\ detected\\ gene\\ g})$\n- $tfidf(g, U_i) = tf(g, U_i) * idf(g)$\n\n## TF-IDF\n\n::: columns\n:::{.column width=\"50%\"}\n![](images/gene_ranks.png)\n:::\n:::{.column width=\"50%\"}\n![](images/tf-idfs.png)\n:::\n:::\n\n\n## Intelligent search using tf-idf\n\n- For every cluster we can calculate in how many cells (percent) every gene is expressed\n- This is basically a cluster \"expression profile\" \n- This information is much more than just markers - we can also see \"background\" expression\n\n\n## Intelligent search using tf-idf\n\n- We could calculate tf-idf vectors for all the clusters (and datasets)\n- The query will have (1) for all genes from the query (-1) for all the genes we want to exclude, and (0) for all other genes\n- We now have to quickly calculate cosine similarity against all the tf-idf vectors for the clusters\n- There are algorithms that allow to do just this\n\n![](images/falconn.png)\n\n::: footer\n\n[Practical and Optimal LSH for Angular Distance](http://papers.nips.cc/paper/5893-practical-and-optimal-lsh-for-angular-distance) Alexandr Andoni, Piotr Indyk, Thijs Laarhoven, Ilya Razenshteyn, Ludwig Schmidt NIPS 2015\n\n[https://github.com/FALCONN-LIB/FALCONN](https://github.com/FALCONN-LIB/FALCONN)\n:::\n\n\n## Plans for scNavigator\n\n- Start processing of a new dump for scNavigator (we need to start obtaining **at least** processed seurat RDS-objects)\n- Implement the prototype for TF-IDF search (do I need to change any code from scNavigator to make it work)\n- Merge /scn-dev/ into /scn/ and make it default\n- Migrate all old objects to new format (possibly with minimal reprocessing)\n- Add new technologies to \"main\" part of the pipeline\n- Add \"minimal\" tests to \"main\" part of the pipeline\n\n\n\n\n\n## Lymphatic Endothelial Cells story\n\n::: columns\n::: {.column width=\"65%\"}\n![](images/lec1.png)\n:::\n\n::: {.column width=\"35%\"}\n![](images/lec2.png)\n:::\n:::\n\n\nMost of the results - Master Thesis of Diana Lupova\n\nIn collaboration with Rafael S. Czepielewski\n\n::: footer\n\nGonzalez-Loyola et al, 2020 - Ad Drug Del Rev\n\nWong et al., 2018 – Dev Cell\n:::\n\n\n## Gene signature search\n\n\nTable 1 - Genes we searched for\n\nTable 2 - We exluded clusters expressing these genes\n\n![](images/genes1.png)\n\n## Search results\n\n::: columns\n:::{.column width=\"50%\"}\nMouse:\n\n- 56 single-cell RNA-seq datasets\n- 279 408 cells from 14 tissues\n- Extracted 2819 lymphatic endothelial cells\n\n![](images/mouse_cells.png)\n:::\n:::{.column width=\"50%\"}\n\nHuman:\n\n- 12 single-cell RNA-seq datasets\n- 140 221 cells from 5 tissues\n- Extracted 2010 lymphatic endothelial cells\n\n![](images/human_cells.png)\n:::\n:::\n\n\n## LEC extraction - mouse cells\n\n![](images/mouse_clustering.png)\n\n\n## LEC extraction - human cells\n\n\n![](images/human_clustering.png)\n\n\n## LEC extraction - mouse literature markers\n\n![](images/markers_mouse.png)\n\n## LEC extraction - human literature markers\n\n![](images/markers_human.png)\n\n## Identification of novel markers\n\n![](images/frequency_scheme.png)\n\n## LEC extraction - mouse literature markers\n\n![](images/markers_mouse_list.png)\n\n## LEC extraction - human literature markers\n\n![](images/markers_human_list.png)\n\n## Recent victories - validation in tissues\n\n",
    "supporting": [
      "lab_meeting_2022_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}